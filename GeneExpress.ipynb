{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwS5eOoyfFcQucic2+t96E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taral0101/DeepGenePredictor/blob/main/GeneExpress.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**"
      ],
      "metadata": {
        "id": "noohtWjmRijT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ax80qASOMvwg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading and Displaying the Dataset**"
      ],
      "metadata": {
        "id": "NVEjCOZxRqbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/GSE234080_H1299_kdEIF3G_TPM0.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Display columns to understand the structure of the dataset\n",
        "print(data.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di2CZFoFNRvb",
        "outputId": "cc0b37b9-8309-45d7-d2a2-fe73893ea46b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['gene_symbol', 'tpm_HC5_1', 'tpm_HC5_2', 'tpm_HC5_3', 'tpm_HC5_input_1',\n",
            "       'tpm_HC5_input_2', 'tpm_HC5_input_3', 'tpm_HNC_1', 'tpm_HNC_2',\n",
            "       'tpm_HNC_3', 'tpm_HNC_input_1', 'tpm_HNC_input_2', 'tpm_HNC_input_3'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing the Data**"
      ],
      "metadata": {
        "id": "93RfYXDFRznb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume the last column is the target variable for gene expression\n",
        "target_column = data.columns[-1]\n",
        "\n",
        "# Separate features and target, EXCLUDING the first column (gene names)\n",
        "X = data.iloc[:, 1:].drop(columns=[target_column]).values  # Start from the second column\n",
        "y = data[target_column].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Normalize the target variable\n",
        "y_mean = y_train.mean()\n",
        "y_std = y_train.std()\n",
        "y_train = (y_train - y_mean) / y_std\n",
        "y_test = (y_test - y_mean) / y_std\n",
        "\n",
        "# Convert the data to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n"
      ],
      "metadata": {
        "id": "viFb8NlrOG3S"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating DataLoaders**"
      ],
      "metadata": {
        "id": "FsbguZ--R-yL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TensorDatasets\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "uKObcQagOZJX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the Linear Regression Model**"
      ],
      "metadata": {
        "id": "CXOQOkLWSP7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LinearRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "model = LinearRegressionModel(input_dim)\n"
      ],
      "metadata": {
        "id": "6ywtHLe4Oclb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting Loss Function and Optimizer**"
      ],
      "metadata": {
        "id": "Zqfc2aDhSTlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function and optimizer with weight decay for regularization\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)\n"
      ],
      "metadata": {
        "id": "BK_BStSzOfMF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the Model**"
      ],
      "metadata": {
        "id": "IwbbA_haSYII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        # Forward pass\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print loss every 10 epochs\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUs-pf6hOhpO",
        "outputId": "216003bf-39c8-4b7b-aba8-59b838f38679"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.0003\n",
            "Epoch [20/100], Loss: 0.0002\n",
            "Epoch [30/100], Loss: 0.0013\n",
            "Epoch [40/100], Loss: 0.0006\n",
            "Epoch [50/100], Loss: 0.1306\n",
            "Epoch [60/100], Loss: 0.0002\n",
            "Epoch [70/100], Loss: 0.0005\n",
            "Epoch [80/100], Loss: 0.0008\n",
            "Epoch [90/100], Loss: 0.0062\n",
            "Epoch [100/100], Loss: 0.0002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluating the Model**"
      ],
      "metadata": {
        "id": "6ffgBFfoSd0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test_tensor)\n",
        "    test_loss = criterion(y_pred, y_test_tensor)\n",
        "    print(f'Test Loss: {test_loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AZivGEhOmuF",
        "outputId": "78a1459e-bdd8-4562-d52b-9c2103450fbb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.0064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementing K-Fold Cross-Validation**"
      ],
      "metadata": {
        "id": "uAxSQvH1ShSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Fold Cross-Validation\n",
        "kf = KFold(n_splits=5)\n",
        "fold_results = []\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
        "    print(f'Fold {fold+1}/{kf.get_n_splits()}')\n",
        "\n",
        "    X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
        "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
        "\n",
        "    # Standardize the features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_fold = scaler.fit_transform(X_train_fold)\n",
        "    X_val_fold = scaler.transform(X_val_fold)\n",
        "\n",
        "    # Normalize the target variable\n",
        "    y_mean = y_train_fold.mean()\n",
        "    y_std = y_train_fold.std()\n",
        "    y_train_fold = (y_train_fold - y_mean) / y_std\n",
        "    y_val_fold = (y_val_fold - y_mean) / y_std\n",
        "\n",
        "    # Convert to tensors\n",
        "    X_train_tensor = torch.tensor(X_train_fold, dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_train_fold, dtype=torch.float32).view(-1, 1)\n",
        "    X_val_tensor = torch.tensor(X_val_fold, dtype=torch.float32)\n",
        "    y_val_tensor = torch.tensor(y_val_fold, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "    # Create TensorDatasets and DataLoaders\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # Define the model\n",
        "    model = LinearRegressionModel(input_dim)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)\n",
        "\n",
        "    # Training loop for the fold\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_val_pred = model(X_val_tensor)\n",
        "            val_loss = criterion(y_val_pred, y_val_tensor)\n",
        "\n",
        "        # Print loss every 10 epochs\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
        "\n",
        "    fold_results.append(val_loss.item())\n",
        "\n",
        "# Average validation loss across folds\n",
        "average_val_loss = sum(fold_results) / len(fold_results)\n",
        "print(f'Average Validation Loss: {average_val_loss:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iei2rDftO78T",
        "outputId": "2f691a51-14ef-40a4-f086-0e92beb455db"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/5\n",
            "Epoch [10/100], Train Loss: 0.0017, Val Loss: 0.0152\n",
            "Epoch [20/100], Train Loss: 0.0010, Val Loss: 0.0125\n",
            "Epoch [30/100], Train Loss: 0.0033, Val Loss: 0.0081\n",
            "Epoch [40/100], Train Loss: 0.0001, Val Loss: 0.0093\n",
            "Epoch [50/100], Train Loss: 0.0002, Val Loss: 0.0061\n",
            "Epoch [60/100], Train Loss: 0.0011, Val Loss: 0.0120\n",
            "Epoch [70/100], Train Loss: 0.0003, Val Loss: 0.0052\n",
            "Epoch [80/100], Train Loss: 0.0004, Val Loss: 0.0075\n",
            "Epoch [90/100], Train Loss: 0.0001, Val Loss: 0.0078\n",
            "Epoch [100/100], Train Loss: 0.0002, Val Loss: 0.0056\n",
            "Fold 2/5\n",
            "Epoch [10/100], Train Loss: 0.0005, Val Loss: 0.0397\n",
            "Epoch [20/100], Train Loss: 0.0002, Val Loss: 0.0291\n",
            "Epoch [30/100], Train Loss: 0.0019, Val Loss: 0.0200\n",
            "Epoch [40/100], Train Loss: 0.0022, Val Loss: 0.0180\n",
            "Epoch [50/100], Train Loss: 0.0003, Val Loss: 0.0173\n",
            "Epoch [60/100], Train Loss: 0.0027, Val Loss: 0.0249\n",
            "Epoch [70/100], Train Loss: 0.0001, Val Loss: 0.0151\n",
            "Epoch [80/100], Train Loss: 0.0007, Val Loss: 0.0153\n",
            "Epoch [90/100], Train Loss: 0.0010, Val Loss: 0.0171\n",
            "Epoch [100/100], Train Loss: 0.0305, Val Loss: 0.0126\n",
            "Fold 3/5\n",
            "Epoch [10/100], Train Loss: 0.0004, Val Loss: 0.0387\n",
            "Epoch [20/100], Train Loss: 0.0013, Val Loss: 0.0208\n",
            "Epoch [30/100], Train Loss: 0.0008, Val Loss: 0.0181\n",
            "Epoch [40/100], Train Loss: 0.0002, Val Loss: 0.0135\n",
            "Epoch [50/100], Train Loss: 0.0021, Val Loss: 0.0135\n",
            "Epoch [60/100], Train Loss: 0.0005, Val Loss: 0.0250\n",
            "Epoch [70/100], Train Loss: 0.0022, Val Loss: 0.0129\n",
            "Epoch [80/100], Train Loss: 0.0016, Val Loss: 0.0110\n",
            "Epoch [90/100], Train Loss: 0.0002, Val Loss: 0.0116\n",
            "Epoch [100/100], Train Loss: 0.0054, Val Loss: 0.0102\n",
            "Fold 4/5\n",
            "Epoch [10/100], Train Loss: 0.0116, Val Loss: 0.0425\n",
            "Epoch [20/100], Train Loss: 0.0004, Val Loss: 0.0212\n",
            "Epoch [30/100], Train Loss: 0.0004, Val Loss: 0.0153\n",
            "Epoch [40/100], Train Loss: 0.0004, Val Loss: 0.0122\n",
            "Epoch [50/100], Train Loss: 0.0003, Val Loss: 0.0069\n",
            "Epoch [60/100], Train Loss: 0.0003, Val Loss: 0.0066\n",
            "Epoch [70/100], Train Loss: 0.0013, Val Loss: 0.0051\n",
            "Epoch [80/100], Train Loss: 0.0002, Val Loss: 0.0037\n",
            "Epoch [90/100], Train Loss: 0.0002, Val Loss: 0.0054\n",
            "Epoch [100/100], Train Loss: 0.0001, Val Loss: 0.0043\n",
            "Fold 5/5\n",
            "Epoch [10/100], Train Loss: 0.0014, Val Loss: 0.0270\n",
            "Epoch [20/100], Train Loss: 0.0021, Val Loss: 0.0108\n",
            "Epoch [30/100], Train Loss: 0.0008, Val Loss: 0.0059\n",
            "Epoch [40/100], Train Loss: 0.0003, Val Loss: 0.0114\n",
            "Epoch [50/100], Train Loss: 0.0014, Val Loss: 0.0039\n",
            "Epoch [60/100], Train Loss: 0.0003, Val Loss: 0.0035\n",
            "Epoch [70/100], Train Loss: 0.0011, Val Loss: 0.0032\n",
            "Epoch [80/100], Train Loss: 0.0002, Val Loss: 0.0034\n",
            "Epoch [90/100], Train Loss: 0.0002, Val Loss: 0.0028\n",
            "Epoch [100/100], Train Loss: 0.0006, Val Loss: 0.0044\n",
            "Average Validation Loss: 0.0074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Evaluation on Test Set**"
      ],
      "metadata": {
        "id": "Q6Rr8GZ5Sl6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final evaluation on the test set after K-Fold cross-validation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test_tensor)\n",
        "    test_loss = criterion(y_pred, y_test_tensor)\n",
        "    print(f'Final Test Loss: {test_loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1NIRf8LO-cO",
        "outputId": "73a620c5-b5f9-4f9b-ac55-bb36a31c925c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Loss: 0.0096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MIxGDCB2P3qt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}